{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TD9Xd6ftg5hL"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d niharika41298/yoga-poses-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oO9_KE7kVHJ",
        "outputId": "bc1671b6-77fc-462f-ab11-2d20e7b8ce87"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yoga-poses-dataset.zip to /content\n",
            " 99% 284M/288M [00:04<00:00, 43.9MB/s]\n",
            "100% 288M/288M [00:04<00:00, 62.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zip_refee=zipfile.ZipFile('/content/yoga-poses-dataset.zip','r')\n",
        "zip_refee.extractall('/content')\n",
        "zip_refee.close()"
      ],
      "metadata": {
        "id": "4qxJplUYk5XD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augumentation"
      ],
      "metadata": {
        "id": "0GQaiolomjiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import Sequential\n",
        "from keras.layers import Dense,Dropout,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from keras.optimizers.schedules import ExponentialDecay"
      ],
      "metadata": {
        "id": "6Xp3hIoomwLH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train='/content/DATASET/TRAIN'\n",
        "test='/content/DATASET/TEST'"
      ],
      "metadata": {
        "id": "NX-g-fu4mZIG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=40,\n",
        "                                   width_shift_range=0.2,\n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   fill_mode='nearest')\n",
        "test_datagen=ImageDataGenerator(rescale=1./255.)\n"
      ],
      "metadata": {
        "id": "deyMOgY3miRp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_size=(255,255)\n",
        "batch_size=32\n",
        "train_generator = train_datagen.flow_from_directory(train,\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')\n",
        "test_generator = test_datagen.flow_from_directory(test,\n",
        "                                                    target_size=img_size,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynq7AQm3piq_",
        "outputId": "452707e4-4a98-4a4b-9f8f-4d8e47ac8724"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1081 images belonging to 5 classes.\n",
            "Found 470 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n"
      ],
      "metadata": {
        "id": "01gd-JnEqv7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedual=ExponentialDecay(initial_learning_rate=1e-3,\n",
        "    decay_steps=1000,\n",
        "    decay_rate=0.9)"
      ],
      "metadata": {
        "id": "VqM-iKzTqtHH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2),strides=2,padding='valid'))\n",
        "\n",
        "\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(256,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2),strides=2,padding='valid'))\n",
        "\n",
        "model.add(Conv2D(512,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D((2,2),strides=2,padding='valid'))\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_generator.class_indices), activation='softmax'))"
      ],
      "metadata": {
        "id": "SueR0Jj2qjdv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lRAx7giRr329",
        "outputId": "8c780f9e-56c8-42d5-f5ab-cad4a7b37149"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 254, 254, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 254, 254, 64)      256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 64)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 128)     73856     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 125, 125, 128)     512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 128)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 60, 60, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 60, 60, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 256)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 28, 28, 512)       2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 14, 14, 512)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              102761472 \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 1024)              4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 256)               262400    \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 256)               1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 128)               512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 64)                256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 104626053 (399.12 MB)\n",
            "Trainable params: 104621189 (399.10 MB)\n",
            "Non-trainable params: 4864 (19.00 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model=keras.saving.load_model('/content/best_model.h5')/# to train model again"
      ],
      "metadata": {
        "id": "Qjy7eKCllVNc"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer= Adam(learning_rate=lr_schedual),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "m_tQF9dsr_Ft"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(factor=0.1, patience=3)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True)"
      ],
      "metadata": {
        "id": "r2zC9MwrsSHp"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import ImageFile\n",
        "\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    validation_data=test_generator,\n",
        "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LA2VOi_sZLt",
        "outputId": "21384e8c-5993-4139-f31f-9116f4ccc654"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "34/34 [==============================] - 61s 2s/step - loss: 0.7349 - accuracy: 0.7345 - val_loss: 0.6725 - val_accuracy: 0.7447 - lr: 9.9653e-04\n",
            "Epoch 2/50\n",
            "34/34 [==============================] - 97s 3s/step - loss: 0.7625 - accuracy: 0.7151 - val_loss: 0.4120 - val_accuracy: 0.8404 - lr: 9.9297e-04\n",
            "Epoch 3/50\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.8601 - accuracy: 0.6892 - val_loss: 2.6090 - val_accuracy: 0.3511 - lr: 9.8941e-04\n",
            "Epoch 4/50\n",
            "34/34 [==============================] - 37s 1s/step - loss: 0.8120 - accuracy: 0.7216 - val_loss: 0.8900 - val_accuracy: 0.6723 - lr: 9.8588e-04\n",
            "Epoch 5/50\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.7903 - accuracy: 0.7142 - val_loss: 0.4375 - val_accuracy: 0.8404 - lr: 9.8235e-04\n",
            "Epoch 6/50\n",
            "34/34 [==============================] - 41s 1s/step - loss: 0.7168 - accuracy: 0.7438 - val_loss: 0.4128 - val_accuracy: 0.8511 - lr: 9.7884e-04\n",
            "Epoch 7/50\n",
            "34/34 [==============================] - 41s 1s/step - loss: 0.7359 - accuracy: 0.7308 - val_loss: 0.8010 - val_accuracy: 0.7106 - lr: 9.7534e-04\n",
            "Epoch 8/50\n",
            "34/34 [==============================] - 40s 1s/step - loss: 0.7415 - accuracy: 0.7401 - val_loss: 0.5982 - val_accuracy: 0.7617 - lr: 9.7185e-04\n",
            "Epoch 9/50\n",
            "34/34 [==============================] - 36s 1s/step - loss: 0.6793 - accuracy: 0.7660 - val_loss: 0.4861 - val_accuracy: 0.8085 - lr: 9.6838e-04\n",
            "Epoch 10/50\n",
            "34/34 [==============================] - 36s 1s/step - loss: 0.7445 - accuracy: 0.7391 - val_loss: 0.5860 - val_accuracy: 0.7787 - lr: 9.6491e-04\n",
            "Epoch 11/50\n",
            "34/34 [==============================] - 38s 1s/step - loss: 0.7219 - accuracy: 0.7530 - val_loss: 0.5740 - val_accuracy: 0.7766 - lr: 9.6146e-04\n",
            "Epoch 12/50\n",
            "34/34 [==============================] - 39s 1s/step - loss: 0.6643 - accuracy: 0.7715 - val_loss: 0.8240 - val_accuracy: 0.6723 - lr: 9.5802e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test data"
      ],
      "metadata": {
        "id": "5oMTMfZJuC7k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "image = cv2.imread(\"/content/DATASET/TEST/goddess/00000000.jpg\")\n",
        "image = cv2.resize(image, (256, 256))  # Adjust the size based on your model requirements\n",
        "image = image / 255.0  # Normalize pixel values\n",
        "image=np.expand_dims(image, axis=0)"
      ],
      "metadata": {
        "id": "w65hHVr5s9Ph"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels = ['downdog', 'goddess', 'plank', 'tree','warrior2']\n",
        "predictions = model.predict(image)\n",
        "predicted_class_index = np.argmax(predictions)\n",
        "predicted_class = class_labels[predicted_class_index]\n",
        "print(predicted_class)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fBzIdm5DqvKd",
        "outputId": "b9b5c3b2-3698-4d52-e2b6-d98259508052"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step\n",
            "plank\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nir8Y4f5rRxh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}